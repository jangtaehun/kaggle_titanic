### ğŸ‘¨â€ğŸ« Titanic - Machine Learning from Disaster
kaggleì—ì„œ ì œê³µí•˜ëŠ” Tatanic dataë¥¼ ì´ìš©í•´ EDAì™€ model í•™ìŠµì„ í†µí•´ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” í”„ë¡œì íŠ¸

---
### â²ï¸ ë¶„ì„ ê¸°ê°„
2024.08.20 - 2024.08.21

---

### ğŸ“ ì†Œê°œ
íƒ€ì´íƒ€ë‹‰ì€ ì„¸ê³„ì—ì„œ ê°€ì¥ ìœ ëª…í•œ ì¹¨ëª°ì„ ì´ë¼ í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ê³ ë¡œë¶€í„° 100ë…„ì´ ë„˜ê²Œ ì§€ë‚œ ì˜¤ëŠ˜ë‚ ê¹Œì§€ë„ ê´€ë ¨ ì—°êµ¬ê°€ í™œë°œí•˜ê²Œ ì´ë£¨ì–´ì§€ë©° ëŒ€ì¤‘ë§¤ì²´ ë“±ì—ì„œ ë§ì´ ë‹¤ë¤„ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë§ì€ ì‚¬ëŒë“¤ì´ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì„ ì²˜ìŒ ì‹œì‘í•  ë•Œ Kaggleì—ì„œ ì œê³µí•˜ëŠ” íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ë¥¼ ì´ìš©í•´ Kaggle ìì²´ ëŒ€íšŒì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ í•„ì ì—­ì‹œ íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ë¥¼ ì´ìš©í•œ Kaggle íƒ€ì´íƒ€ë‹‰ ëŒ€íšŒì— ì°¸ì—¬í•´ ê°€ëŠ¥í•œ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ì–´ë³´ê³ ì ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

---

### í”„ë¡œì íŠ¸ ê°œìš”
##### ğŸ“Œ ëª©í‘œ
ì´ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” íƒ€ì´íƒ€ë‹‰ íƒ‘ìŠ¹ê°ì˜ ìƒì¡´ ì—¬ë¶€ë¥¼ ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ íƒ‘ìŠ¹ê°ì˜ ì¸êµ¬í†µê³„, í‹°ì¼“ ë“±ê¸‰, ì„ ì‹¤ ì •ë³´ ë“±ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì§•ë“¤ì„ ë¶„ì„í•¨ìœ¼ë¡œì¨, íƒ‘ìŠ¹ê°ì˜ ìƒì¡´ ì—¬ë¶€ë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³ ì í•©ë‹ˆë‹¤.

##### ğŸ–¥ï¸ ë°ì´í„°ì…‹ (Data Set)
ì´ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì€ Kaggleì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ìŒ íŒŒì¼ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
1. titanic_train.csv: í›ˆë ¨ ë°ì´í„°ì…‹, íŠ¹ì§•ë“¤ê³¼ ëª©í‘œ ë³€ìˆ˜(Survived)ë¥¼ í¬í•¨.
2. test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹, ì˜ˆì¸¡ì„ ìœ„í•´ ì‚¬ìš©ë  ë°ì´í„°.
3. gender_submission.csv: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œí•˜ê¸° ìœ„í•œ ìƒ˜í”Œ íŒŒì¼.

---

##### ë°©ë²•ë¡ 
1. titanicì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
  * ë¬¸ì œ ì •ì˜
  * ë¶„ì„ ëŒ€ìƒì— ëŒ€í•œ ì´í•´
2. titanic data setì„ ì´ìš©í•œ EDA
  * ê³µí†µ ì½”ë“œ
  * titanic dataì— ëŒ€í•œ ê¸°ë³¸ì ì¸  ì •ë³´
  * í†µê³„ ë° ì‹œê°í™”
    * ì—¬ì„±ê³¼ ì•„ì´ë“¤
    * ë‚˜ì´
    * ì‚¬íšŒì  ì§€ìœ„
    * Embarked(ì¤‘ê°„ ì •ì°© í•­êµ¬)
    * Cabin(ì„ ì‹¤ ë²ˆí˜¸)
    * SibSp, Parch(ê°™ì´ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤ ë˜ëŠ” ë°°ìš°ì ì¸ì›ìˆ˜, ê°™ì´ íƒ‘ìŠ¹í•œ ë¶€ëª¨ë‹˜ ë˜ëŠ” ì–´ë¦°ì´ ì¸ì›ìˆ˜)
3. ëª¨ë¸ í•™ìŠµ
  * RandomForest
  * XGBoost
  * LightGBM
  * CatBoost
4. ê²°ë¡ 
  * í•œê³„ì 

---

#### titanicì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
   ##### ë¬¸ì œ ì •ì˜
titanic data setì„ ì´ìš©í•œ Kaggleì—ì„œ ì§„í–‰í•˜ëŠ” ëŒ€íšŒëŠ” ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì´ë‹¤.
* PassengerId: íƒ‘ìŠ¹ì ë°ì´í„° ì¼ë ¨ë²ˆí˜¸
* Survived: ìƒì¡´ ì—¬ë¶€, 0 = ì‚¬ë§, 1 = ìƒì¡´
* Pclass: í‹°ì¼“ì˜ ì„ ì‹¤ ë“±ê¸‰, 1 = ì¼ë“±ì„, 2 = ì´ë“±ì„, 3 = ì‚¼ë“±ì„
* Sex: íƒ‘ìŠ¹ì ì„±ë³„
* Name: íƒ‘ìŠ¹ì ì´ë¦„
* Age: íƒ‘ìŠ¹ì ë‚˜ì´
* SibSp: ê°™ì´ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤ ë˜ëŠ” ë°°ìš°ì ì¸ì›ìˆ˜
* Parch: ê°™ì´ íƒ‘ìŠ¹í•œ ë¶€ëª¨ë‹˜ ë˜ëŠ” ì–´ë¦°ì´ ì¸ì›ìˆ˜
* Ticket: í‹°ì¼“ ë²ˆí˜¸
* Fare: ìš”ê¸ˆ
* Cabin: ì„ ì‹¤ ë²ˆí˜¸
* Embarked: ì¤‘ê°„ ì •ì°© í•­êµ¬, C = Cherbourg, Q = Queenstown, S = Southampton
titanic_train.csvì„ ê¸°ë°˜ìœ¼ë¡œ titanicì— ëŒ€í•œ ì§€ì‹ê³¼ ì ì ˆí•œ EDAë¥¼ ì§„í–‰í•œ í›„ test.csvì˜ ë°ì´í„°ë¥¼ ì´ìš©í•´ ì˜ˆì¸¡í•œ í›„ ê²°ê³¼ë¥¼ gender_submission.csvì™€ ê²°í•©í•œ í›„ ì œì¶œí•˜ê³  ì œì¶œí•˜ëŠ” ë¬¸ì œì´ë‹¤.
   ##### ë¶„ì„ ëŒ€ìƒì— ëŒ€í•œ ì´í•´
titanic data setì„ ì´ìš©í•œ Kaggleì—ì„œ ì§„í–‰í•˜ëŠ” ëŒ€íšŒëŠ” ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì´ë‹¤.
* ê¸¸ì´: 269.1m
* í­: 28m
* ë†’ì´: 53.3m
* ë°°ìˆ˜ëŸ‰: 52,310t
* ì´ í†¤ìˆ˜: 46,328 GRT
* ìµœëŒ€ ì†ë„: 23ë…¸íŠ¸ (43ã/h)
* ìµœëŒ€ íƒ‘ìŠ¹ ê°€ëŠ¥ ì¸ì› = 3,547ëª…(ìŠ¹ì„ ê°, ìŠ¹ë¬´ì› ëª¨ë‘ í¬í•¨)
* ì„ ì‹¤ ìˆ˜
  * 1st-class(1ë“±ì‹¤): 416ê°œ
  * 2nd-class(2ë“±ì‹¤): 162ê°œ
  * 3rd-class(3ë“±ì‹¤): 269ê°œ
  * cabin area(ì „ìš©ì‹¤, ê°‘íŒì‹¤ ë“±): 40ê°œ
* ì¸µë³„ êµ¬ì¡°
   * ë³´íŠ¸ ê°‘íŒ: ìµœìƒì¸µìœ¼ë¡œ êµ¬ëª…ë³´íŠ¸ê°€ ë°°ì¹˜ë˜ì–´ ìˆë‹¤.
   * ì‚°ì±…ë¡œê°€ ìˆìœ¼ë©°, 1ë“±ì‹¤, 2ë“±ì‹¤, ìƒì„ ì‚¬ê´€ ë“± ì‚°ì±…ë¡œì˜ ì˜ì—­ì´ ì •í•´ì ¸ ìˆë‹¤.
   * 1ë“±ì‹¤ ì‚°ì±…ë¡œëŠ” êµ¬ëª…ì •ì´ ë¹„ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤.
   * Aê°‘íŒ: ì‚°ì±… ê°‘íŒ
   * ê±°ì˜ ëª¨ë“  ì˜ì—­ì´ 1ë“±ì‹¤ ì „ìš©ì´ì—ˆë‹¤.
  * Bê°‘íŒ: ì„ êµë£¨ ê°‘íŒ
    * ê°ì‹¤ì€ ëª¨ë‘ 1ë“±ì‹¤ì´ì˜€ìœ¼ë©° 2ê°œì˜ íŠ¹ë³„ ê°ì‹¤ë“¤ì€ ì „ìš© í…Œë¼ìŠ¤ ë° ì‚°ì±…ë¡œë¥¼ ë³´ìœ í–ˆë‹¤.
  * Cê°‘íŒ
    * ì„ ë‘ - ì„ ì›ë“¤ì˜ ìˆ™ì†Œ
    * ì„ ë¯¸ - 3ë“±ì‹¤ ì „ìš© íœ´ê²Œì‹¤
  * Dê°‘íŒ: ê³µê³µì‹œì„¤
    * 1ë“±ì‹¤ ëŒ€í•©ì‹¤
    * 2ë“±ì‹¤ ì‹ë‹¹, 2ë“±ì‹¤ ì‹ë‹¹
    * 3ë“±ì‹¤ì„ ìœ„í•œ ê³µê°„ë„ ë§ˆë ¨ë˜ì–´ ìˆì–´ ì—°íšŒ ì¥ì†Œë¡œ ì‚¬ìš©
  * Eê°‘íŒ
    * 1, 2, 3ë“±ì‹¤ ëª¨ë‘ì˜ ê°ì‹¤ë“¤ê³¼ ì„ ì›ë“¤ì˜ ìˆ™ì†Œ
  * Fê°‘íŒ
    * ê°ì‹¤ì€ 3ë“±ì‹¤ì´ ëŒ€ë¶€ë¶„ì´ë©° 2ë“±ì‹¤, ì„ ì›ë“¤ì˜ ìˆ™ì†Œë„ ìˆì—ˆë‹¤.
  * Gê°‘íŒ
    * ìˆ˜ë©´ ìœ„ì—ì„œ ê°€ì¥ ë‚®ì€ ì¸µìœ¼ë¡œ ì„ ì›, 3ë“±ì‹¤ ìŠ¹ê°ë“¤ì˜ ê°ì‹¤ì´ ìˆëŠ” ê°€ì¥ ë‚®ì€ ê°‘íŒ
  * ìµœí•˜ ê°‘íŒ
    * ì°½ê³ ê°€ ìœ„ì¹˜í•œ ì¥ì†Œ
    * íƒ±í¬ í†±
    * ë³´ì¼ëŸ¬ì‹¤ê³¼ ê¸°ê´€ì‹¤ì´ ìœ„ì¹˜í•œ ì¥ì†Œ
* ìŠ¹ê°
  * ì´ 1,317ëª…
  * 1ë“±ì‹¤ - 329ëª…
    * ë¶€ìœ í•œ ìŠ¹ê°ë“¤ì´ ì£¼ë¡œ íƒ€ê³  ìˆì—ˆë‹¤.
    * ê°ì‹¤ - ë³´íŠ¸ ê°‘íŒ(ìµœìƒì¸µ) ~ Eê°‘íŒ(ìƒê°‘íŒ)
  * 2ë“±ì‹¤ - 285ëª…
    * ì¤‘ì‚°ì¸µ ìŠ¹ê°ë“¤ì´ ì£¼ë¡œ íƒ€ê³  ìˆì—ˆë‹¤.
    * ê°ì‹¤ - D ~ F
  * 3ë“±ì‹¤ - 710ëª…
    * ê°€ë‚œí•œ ìŠ¹ê°ë“¤ì´ ì£¼ë¡œ íƒ€ê³  ìˆì—ˆë‹¤.
    * ë‹¹ì‹œ ê¸°ì¤€ìœ¼ë¡œ í•˜ì¸µë¯¼ë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•´ ê±´ê°•ìƒíƒœê°€ ì¢‹ì§€ ì•Šì•˜ìœ¼ë©° ì´ë¯¼ìë“¤ì´ ë§ì•˜ë˜ ë§Œí¼ ë°°ì— íƒ‘ìŠ¹í•˜ê¸° ì „ì—ëŠ” ê²€ì—­ ê³¼ì •ì„ ê±¸ì³¤ë‹¤.
    * ì—¬ìì™€ ë‚¨ìëŠ” ë°°ì˜ ì•ë¨¸ë¦¬ì™€ ë’·ë¨¸ë¦¬ì— ê°ê° ë”°ë¡œ ë–¨ì–´ì ¸ ìŠ¹ì„ í–ˆìœ¼ë‚˜ ê°€ì¡± ë‹¨ìœ„ì¼ ê²½ìš° ê°™ì´ ìŠ¹ì„ í•  ìˆ˜ ìˆì—ˆë‹¤.
* ìš”ê¸ˆ
   * 1ë“±ì„: 30íŒŒìš´ë“œ(150ë‹¬ëŸ¬), ìŠ¤ìœ„íŠ¸ 1ë“±ì„ì€ 870íŒŒìš´ë“œ(4350ë‹¬ëŸ¬)
   * 2ë“±ì„: 12íŒŒìš´ë“œ(60ë‹¬ëŸ¬)
   * 3ë“±ì„: 7íŒŒìš´ë“œ(35ë‹¬ëŸ¬)
* ì¤‘ê°„ ì •ì°© í•­êµ¬ ë° ìµœì¢… ì •ì°© í•­êµ¬
   * S = ì˜êµ­ Southampton
   * C = í”„ë‘ìŠ¤ Cherbourg
   * Q = ì•„ì¼ëœë“œ Queenstown
   * ìµœì¢… ì •ì°© í•­êµ¬ = ë¯¸êµ­ New York
 
   *  ***ìŠ¹ë¬´ì›ì˜ ê²½ìš° ê°‘íŒë¶€, ê¸°ê´€ë¶€, ì‚¬ì£¼ë¶€ê°€ ìˆìœ¼ë‚˜ Kaggleì—ì„œ ì œê³µí•˜ëŠ” data setì—ì„œëŠ” ìŠ¹ë¬´ì›ë“¤ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì— ìƒëµí•˜ê² ìŠµë‹ˆë‹¤.***

* ì¶©ëŒ ë° íƒˆì¶œ
   * ìš°í˜„ì¸¡ë©´ì´ ë¹™ì‚°ê³¼ ì¶©ëŒ
   * ì„ ì›ë“¤ì´ ì—¬ìì™€ ì•„ì´ë“¤ì„ ë¨¼ì € íƒœìš¸ ê²ƒì„ ê±´ì˜í–ˆìœ¼ë©°, ì„ ì¥ì€ ìŠ¹ì¸í–ˆë‹¤. í•˜ì§€ë§Œ ì†Œí†µì˜ ì˜¤ë¥˜ë¡œ â€˜ì—¬ì„±ê³¼ ì•„ì´ë“¤ë§Œâ€™ìœ¼ë¡œ ì „ë‹¬ë˜ì–´ ì—¬ì„±ê³¼ ì–´ë¦°ì´ë§Œ íƒœì› ê¸° ë•Œë¬¸ì— ìë¦¬ê°€ ìˆì—ˆìŒì—ë„ ë‚¨ìëŠ” ìŠ¹ë¬´ì›ë“¤ì´ ê±°ë¶€í•´ êµ¬ëª…ë³´íŠ¸ ì •ì›ì˜ ì ˆë°˜ë„ ëª» íƒœìš´ì±„ ë³´íŠ¸ê°€ ìˆì—ˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ 1,178ëª… ì •ë„ë¥¼ íƒœìš¸ ìˆ˜ ìˆëŠ” êµ¬ëª…ë³´íŠ¸ë§Œ êµ¬ë¹„ë˜ì–´ ìˆì—ˆê¸° ë•Œë¬¸ì— í° ì¸ëª… í”¼í•´ê°€ ë°œìƒí–ˆë‹¤.

---

#### titanic data setì„ ì´ìš©í•œ EDA
titanicì— ëŒ€í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬ì„±ê³¼ ì•„ì´ë“¤ì˜ êµ¬ì¡°ìœ¨ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ â€˜ì—¬ì„±ê³¼ ì•„ì´ë“¤â€™ì— ì§‘ì¤‘ì„ í•´ì„œ í†µê³„ ë° ì‹œê°í™”ë¥¼ ì§„í–‰ë³´ê³ ì í•œë‹¤. ì´ë¥¼ ìœ„í•´ ë‚˜ì´ì™€ ì„±ë³„ì— í•´ë‹¹í•˜ëŠ” featureë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ â€˜ì—¬ì„±ê³¼ ì•„ì´ë“¤â€™ì—ë§Œ ì´ˆì ì„ ë§ì¶”ëŠ” ê²ƒì´ ì•„ë‹Œ ì‚¬íšŒì  ì§€ìœ„ì— ë”°ë¥¸ êµ¬ì¡°ìœ¨ë„ í™•ì¸í•´ ë³¼ ì˜ˆì •ì´ë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
1. ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ì„ ìˆ˜ë¡ ë°° ìœ„ìª½ì— ìœ„ì¹˜í•´ ìˆë‹¤. ì¦‰, ë¹™ì‚°ì´ ì¶©ëŒí•œ ë°° í•˜ì¸µ ë¶€ë¶„ì— ë¹„í•´ ìƒì¸µ ë¶€ë¶„ì€ ëŒ€í”¼í•  ìˆ˜ ìˆëŠ” ì‹œê°„ì´ ì¶©ë¶„í–ˆë‹¤ê³  íŒë‹¨í•˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.
2. ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ë‹¤ëŠ” ê²ƒì€ ë‹¹ì‹œ ì‚¬íšŒì  ì§€ìœ„ê°€ ìƒë‹¹íˆ ë†’ë‹¤ëŠ” ê²ƒì´ë‹¤. ì¦‰, ê·¸ë§Œí¼ì˜ ëŒ€ìš°ë¥¼ ë°›ì•˜ë‹¤ê³  ìƒê°í•˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.
ìœ„ì˜ ë‘ ê°€ì§€ ì´ìœ ë¡œ ì‚¬íšŒì  ì§€ìœ„ì— ë”°ë¥¸ êµ¬ì¡°ìœ¨ë„ í™•ì¸í•´ ë³´ê³ ì í•œë‹¤. ì´ë¥¼ ìœ„í•´ ì„ ì‹¤ ë“±ê¸‰ê³¼, ìš”ê¸ˆì— í•´ë‹¹í•˜ëŠ” featureë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤.

---

   ##### ê³µí†µ ì½”ë“œ
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

train_df = pd.read_csv('./titanic/titanic_train.csv')
predict_df = pd.read_csv('./titanic/test.csv')
gender_submission_df = pd.read_csv('./titanic/gender_submission.csv')
```
kaggleì—ì„œ ì œê³µí•˜ëŠ” titanic dataë¥¼ ë¶ˆëŸ¬ë“¤ì´ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ì½”ë“œë¡œ ì•ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” dataì™€ í•´ë‹¹ dataë¥¼ ê°ê° train_df, predict_df, gender_submissionìœ¼ë¡œ ì„ ì–¸í•œ ë¶€ë¶„ì´ë‹¤.

   ##### titanic data setì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì •ë³´
```
print("train_df ë°ì´í„°ì˜ í–‰ ê°œìˆ˜:", len(train_df))
print('train_df: ë°ì´í„° ì„¸íŠ¸ Null ê°’ ê°¯ìˆ˜ ',train_df.isnull().sum().sum())
print(train_df.isnull().sum())
print(train_df.columns)
print("------------------------------------------------------------ \n\n")

print("predict_df ë°ì´í„°ì˜ í–‰ ê°œìˆ˜:", len(predict_df))
print('predict_df: ë°ì´í„° ì„¸íŠ¸ Null ê°’ ê°¯ìˆ˜ ',predict_df.isnull().sum().sum())
print(predict_df.isnull().sum())
print(predict_df.columns)
print("------------------------------------------------------------ \n\n")
```
![image](https://github.com/user-attachments/assets/58009547-1ccf-4088-966c-4cf510d0a057)

ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. train_dfì—ëŠ” ì´ 12ê°œì˜ featureê°€ ìˆìœ¼ë©°, Ageì— 177ê°œ, Cabinì— 687ê°œ, Embarkedì— 2ê°œì˜ NaN ê°’ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. test_dfì—ë„ NaN ê°’ì´ ìˆì§€ë§Œ, train_dfì™€ ê°™ì€ featureì— ìˆëŠ” ê²ƒì„ í†µí•´ train_dfì—ì„œ NaN ê°’ì„ ì œê±°í•˜ê³ ì í•œ ë°©ë²•ì„ ê·¸ëŒ€ë¡œ ì ìš©í•˜ë©´ ë  ê²ƒì´ë¼ê³  íŒë‹¨ëœë‹¤.

ë˜í•œ, ì°¾ì•„ ë³¼ ìˆ˜ ìˆëŠ” ì ìœ¼ë¡œ íƒ€ì´íƒ€ë‹‰ì—ëŠ” ì„ ì›ë“¤ì„ ì œì™¸í•œ ì´ 1,317ëª…ì´ íƒ‘ìŠ¹í–ˆì§€ë§Œ train_df, test_dfë¥¼ í•©ì³¤ì„ ë•Œ ì´ 1,309ëª…ìœ¼ë¡œ 8ëª…ì´ ì—†ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” titanic dataë¥¼ ì œê³µí•œ kaggleë§Œì´ ì´ìœ ë¥¼ ì•Œ ê²ƒì´ë‹¤.

   ##### í†µê³„ ë° ì‹œê°í™”
1. ì—¬ì„±ê³¼ ì•„ì´ë“¤
   
ì—¬ì„±ì˜ êµ¬ì¡°ìœ¨ì„ í™•ì¸í•˜ê¸° ë¨¼ì € í™•ì¸í•´ì•¼ í•  ê²ƒì€ ì—¬ì„±ê³¼ ë‚¨ì„±ì˜ ìˆ˜ë¥¼ í™•ì¸í•´ ë³´ëŠ” ê²ƒì´ë‹¤.
```
train_df['Sex'].value_counts()
```
ë‚¨ì„±ì€ 577ëª…, ì—¬ì„±ì€ 314ëª…ìœ¼ë¡œ ì´ 891ëª…ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ í™•ì¸í•´ ë³´ê² ë‹¤.
```
print(train_df.groupby(['Sex','Survived'])['Survived'].count())
print("\n-------------------------------------------------------------\n")

female = train_df[train_df['Sex'] == 'female'].shape[0]
female_0 = train_df[(train_df['Sex'] == 'female') & (train_df['Survived'] == 0)].shape[0]
female_1 = train_df[(train_df['Sex'] == 'female') & (train_df['Survived'] == 1)].shape[0]

male = train_df[train_df['Sex'] == 'male'].shape[0]
male_0 = train_df[(train_df['Sex'] == 'male') & (train_df['Survived'] == 0)].shape[0]
male_1 = train_df[(train_df['Sex'] == 'male') & (train_df['Survived'] == 1)].shape[0]

print(f"ì—¬ì„± ìƒì¡´ë¥ : {round(female_1 / (female_0 + female_1) * 100, 2)}")
print(f"ë‚¨ì„± ìƒì¡´ë¥ : {round(male_1 / (male_0 + male_1) * 100, 2)}")
```
ì—¬ì„±ì€ 81ëª…ì´ ì‚¬ë§, 233ëª…ì´ ìƒì¡´í–ˆë‹¤. ë°˜ë©´ ë‚¨ì„±ì€ 468ëª…ì´ ì‚¬ë§, 109ëª…ì´ ìƒì¡´í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ ë‚˜íƒ€ë‚œ ìˆ˜ì¹˜ë¥¼ ë¹„ìœ¨ì„ í†µí•´ì„œ ë‚¨ì—¬ êµ¬ì¡°ìœ¨ì„ ë¹„êµí•˜ë©´ ì—¬ì„± ìƒì¡´ë¥ : 74.2 / ë‚¨ì„± ìƒì¡´ë¥ : 18.89ë¡œ ì—¬ì„±ì˜ êµ¬ì¡°ìœ¨ì´ ë‚¨ì„±ì˜ êµ¬ì¡°ìœ¨ë³´ë‹¤ ì›”ë“±íˆ ë†’ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì‹œê°í™”ë¥¼ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
```
custom_palette = ["#FFA07A", "#AFEEEE"]
sns.barplot(x='Sex', y = 'Survived', data=train_df, palette=custom_palette)
```
![image](https://github.com/user-attachments/assets/949e599b-427c-4d1a-b1f8-7fc84a710f52)


2. ë‚˜ì´
   
ì—¬ì„±ì˜ êµ¬ì¡°ìœ¨ì´ ë‚¨ì„±ë³´ë‹¤ ì›”ë“±íˆ ë†’ë‹¤ëŠ” ê²ƒì€ í™•ì¸ì´ ë˜ì—ˆë‹¤. ì´ì œ ì•„ì´ë“¤ì— ëŒ€í•œ êµ¬ì¡°ìœ¨ì´ ì–´ë¥¸ë³´ë‹¤ ë†’ì€ì§€ í™•ì¸í•´ ë³´ê² ë‹¤.
```
train_df.groupby(['Age', 'Survived'])['Survived'].count()
```
![image](https://github.com/user-attachments/assets/7954da53-71ca-4c87-bfa9-a122e09dd2ad)

kaggleì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ëŠ” ë‚˜ì´ì— ëŒ€í•œ ìë£Œê°€ ìœ„ì™€ ê°™ì´ êµ‰ì¥íˆ ë³µì¡í•˜ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ë”°ë¼ì„œ ë¶„ì„ì— ì•ì„œ ì´ëŸ¬í•œ ë‚˜ì´ë¥¼ êµ¬ë¶„í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•˜ë ¤ê³  í•œë‹¤. íŠ¹íˆ, ë‚˜ì´ì—ëŠ” 177ê°œì˜ NaN ê°’ì´ í¬í•¨ë˜ì–´ ìˆë‹¤. ë”°ë¼ì„œ Ageì˜ NaN ê°’ ë˜í•œ í•´ê²°í•´ì•¼í•  ë¬¸ì œì´ë‹¤. í•„ìëŠ” Ageì— ìˆëŠ” NaN ê°’ë“¤ì„ ê° ê°ì‹¤ ë“±ê¸‰ì˜ í‰ê·  ë‚˜ì´ë¥¼ ëŒ€ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ë ¤ê³  í•œë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 1ë“±ì‹¤ì˜ ê²½ìš° ë¶€ìœ í•œ ê·€ì¡± ê³„ì¸µì´ íƒ‘ìŠ¹í•œ ì„ ì‹¤ë¡œ ì–´ëŠì •ë„ ë‚˜ì´ê°€ ìˆëŠ” ì‚¬ëŒë“¤ì´ ë§ì´ íƒ‘ìŠ¹í•˜ê³  ìˆë‹¤ê³  íŒë‹¨í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ë°˜ë©´, 3ë“±ì‹¤ì˜ ê²½ìš° ê°€ë‚œí•œ ì‚¬ëŒë“¤ì´ íƒ‘ìŠ¹í•œ ì„ ì‹¤ë¡œ ì•„ë©”ë¦¬ì¹¸ ë“œë¦¼ì„ ê¿ˆê¾¸ê³  íƒ€ì´íƒ€ë‹‰í˜¸ì˜ ë§ˆì§€ë§‰ ì •ì°©ì§€ì¸ ë‰´ìš• ì¦‰, ë¯¸êµ­ìœ¼ë¡œ í–¥í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë§ì•˜ë‹¤ê³  íŒë‹¨í•˜ê³  ìˆë‹¤. ë”°ë¼ì„œ 3ë“±ì‹¤ì˜ ê²½ìš° ì Šì€ ì‚¬ëŒë“¤ì´ ë§ì„ ê²ƒìœ¼ë¡œ ìƒê°í•˜ê³  ìˆë‹¤. 2ë“±ì‹¤ì˜ ê²½ìš° ì¤‘ì‚°ì¸µì´ ë§ì€ ì„ ì‹¤ë¡œ 1ë“±ì‹¤, 3ë“±ì‹¤ì˜ ì¤‘ê°„ìœ¼ë¡œ í‰ê·  ë‚˜ì´ ì—­ì‹œ ì¤‘ê°„ìœ¼ë¡œ ìƒê°í•˜ê³  NaN ê°’ì„ ì²˜ë¦¬í•˜ë ¤ê³  í•œë‹¤.
```
nan_age_df = train_df[train_df['Age'].isna()]
nan_counts_by_pclass = nan_age_df.groupby(['Pclass'])['PassengerId'].count()
nan_counts_by_pclass
```
1ë“±ì‹¤ì—ëŠ” 30ëª…, 2ë“±ì‹¤ì—ëŠ” 11ëª…, 3ë“±ì‹¤ì—ëŠ” 136ëª…ì˜ ìŠ¹ê°ë“¤ì´ Ageê°€ NaN ê°’ì´ë¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë“¤ì˜ ë‚˜ì´ë¥¼ ìœ„ì—ì„œ ì„¤ëª…í–ˆë˜ ë°©ë²•ì„ í† ëŒ€ë¡œ ê° ì„ ì‹¤ ë“±ê¸‰ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ë ¤ê³  í•œë‹¤.
```
average_pclass = train_df.groupby('Pclass')['Age'].mean()
train_df['Age'] = train_df.apply(lambda row: average_pclass[row['Pclass']] if pd.isna(row['Age']) else row['Age'], axis=1)
# NaN ê°’ í™•ì¸
train_df['Age'].isna().sum()
```
Ageì— ëŒ€í•œ NaN ê°’ì„ ì²˜ë¦¬í–ˆìœ¼ë‹ˆ ì—°ë ¹ëŒ€ì— ë”°ë¼ êµ¬ë¶„ì„ í•´ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜ëˆ„ë ¤ê³  í•œë‹¤. ê¸°ì¤€ì€ í˜„ì¬ ëŒ€í•œë¯¼êµ­ì„ ê¸°ì¤€ìœ¼ë¡œ í–ˆë‹¤. ë‹¹ì‹œ ì‹œëŒ€ ìƒì— ë§ì§€ ì•Šë‹¤ëŠ” í•œê³„ê°€ ìˆì§€ë§Œ ìë£Œì¡°ì‚¬ì˜ í•œê³„ë¡œ ì¸í•´ í˜„ì¬ ëŒ€í•œë¯¼êµ­ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„í•˜ì˜€ë‹¤. ì´ˆë“±í•™êµ ì…í•™ ì „ê¹Œì§€ë¥¼ Baby, ì¤‘í•™êµ ì…í•™ ì „ê¹Œì§€ë¥¼ Childë¡œ ê³ ë“±í•™êµ ì¡¸ì—… ì „ ì¦‰, ê³ 3ê¹Œì§€ë¥¼ Teenagerë¡œ êµ¬ë¶„í•˜ì˜€ë‹¤. ì´í›„ ë‚¨ì„± í‰ê·  ëŒ€í•™ ì¡¸ì—… ë‚˜ì´ì¸ 26ê¹Œì§€ë¥¼ Studentë¡œ ê·¸ ì´í›„ë¶€í„° ëŒ€í•œë¯¼êµ­ í†µê³„ì²­ ìë£Œì— ë”°ë¼ 39ì„¸ê¹Œì§€ë¥¼ ì²­ë…„ì¸µ(Young Adult)ìœ¼ë¡œ êµ¬ë¶„í–ˆë‹¤. ì´í›„ 64ì„¸ê¹Œì§€ë¥¼ ì¤‘ì¥ë…„ì¸µ(Adult)ë¡œ ê·¸ ì´í›„ëŠ” ë…¸ë…„ì¸µ(Elderly)ë¡œ êµ¬ë¶„í–ˆë‹¤.
```
def get_category(age):
    cat = ''
    if age <= -1: cat = 'Unknown'
    elif age <= 8: cat = 'Baby'
    elif age <= 13: cat = 'Child'
    elif age <= 19: cat = 'Teenager'
    elif age <= 26: cat = 'Student'
    elif age <= 39: cat = 'Young Adult'
    elif age <= 64: cat = 'Adult'
    else: cat = 'Elderly'        
    return cat

group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']
 
train_df['Age_range'] = train_df['Age'].apply(lambda x : get_category(x))
predict_df['Age_range'] = predict_df['Age'].apply(lambda x : get_category(x))
```
ì—°ë ¹ëŒ€ì„ êµ¬ë¶„í•˜ê³  ë‚˜ì„œ ì—°ë ¹ëŒ€ë³„ ì„ ì‹¤ ë“±ê¸‰ì„ ì¶œë ¥í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
```
age_range_pclass = train_df.groupby(['Age_range', 'Pclass']).size().unstack()
age_range_pclass
```
![image](https://github.com/user-attachments/assets/4de00361-4d4c-4c34-860b-ee61bb6b7874)

NaN ê°’ì„ ê° Pclassë³„ í‰ê·  ë‚˜ì´ë¡œ ëŒ€ì²´í–ˆê¸° ë•Œë¬¸ì— Young Adult, Adultì˜ ê°’ì´ ë§ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë˜í•œ, 1ë“±ì‹¤ì— Adultì˜ ë¹„ìœ¨ì´, 3ë“±ì‹¤ì— Young Adultê°€ ë§ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ Baby, Child, Teenagerì˜ ìˆ˜ê°€ ë§ì€ ê²ƒì„ í†µí•´ ê°€ì¡± ë‹¨ìœ„ë¡œ ë§ì´ íƒ‘ìŠ¹í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì—°ë ¹ëŒ€ë³„ ìƒì¡´ìë¥¼ ì‹œê°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 
```
plt.figure(figsize=(10,6))
sns.barplot(x='Age_range', y = 'Survived', hue='Sex', data=train_df, order=group_names)
```
![image](https://github.com/user-attachments/assets/d51fd634-b4a0-4eb2-9909-5e265e0bf12f)

Babyì™€ Child ë¶€ë¶„ì—ì„œì˜ ì—¬ì„±, ë‚¨ì„± ëª¨ë‘ êµ¬ì¡°ìœ¨ì´ ë†’ì€ ê²ƒì„ í†µí•´ ì•„ì´ë“¤ì´ ìš°ì„ ì ìœ¼ë¡œ êµ¬ì¡°ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ëª¨ë“ . ì—°ë ¹ëŒ€ì—ì„œ ì—¬ì„±ì˜ ìƒì¡´ë¥ ì´ ë†’ì€ ê²ƒì„ í†µí•´ ì—¬ì„±ì„ ìš°ì„ ì ìœ¼ë¡œ êµ¬ì¡°í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ Childì—ì„œ êµ¬ì¡°ìœ¨ì´ ë‚®ì€ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¥¼ ì§ì‘í•´ ë³¼ ìˆ˜ ìˆë‹¤. ë°‘ì˜ ì½”ë“œë¥¼ í†µí•´ Childì¼ ê²½ìš° ì–´ë–¤ ì„ ì‹¤ ë“±ê¸‰ì— ì†í•œì§€ í™•ì¸í•´ ë³´ë©´ 1ë“±ê¸‰ì‹¤ì— 1ëª…, 2ë“±ê¸‰ì‹¤ì— 1ëª…, 3ë“±ê¸‰ì‹¤ì— 15ëª…ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ëŒ€ë¶€ë¶„ì´ ë‚®ì€ ì„ ì‹¤ ë“±ê¸‰ì— ì†í•´ êµ¬ì¡°ìœ¨ì´ ë‚®ì•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì¦‰, ì„ ì‹¤ ë“±ê¸‰ì´ êµ¬ì¡°ìœ¨ì— ì˜í–¥ì„ ì£¼ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´í›„ Teenagerë¶€í„° ì–´ë¦°ì´ë¡œ ì·¨ê¸‰ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë‚¨ì„±ì˜ êµ¬ì¡°ìœ¨ì´ ê¸‰ê²©í•˜ê²Œ ë‚®ì•„ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ì ì„ í†µí•´ ì—°ë ¹ëŒ€ê°€ ì ë‹¹íˆ êµ¬ë¶„ë˜ì—ˆë‹¤ëŠ” ê²ƒë„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
age_range_pclass_distribution = train_df.groupby(['Age_range', 'Pclass']).size().unstack()
child_pclass_distribution = age_range_pclass_distribution.loc['Child']
child_pclass_distribution
```


3. ì‚¬íšŒì  ì§€ìœ„
   
ì‚¬íšŒì  ì§€ìœ„ì— ë”°ë¥¸ ë¹„êµëŠ” Pclass(ì„ ì‹¤ ë“±ê¸‰)ì™€ Fare(ìš”ê¸ˆ)ì„ í†µí•´ í•  ìˆ˜ ìˆë‹¤. í•„ìëŠ” ë³¸ë¬¸ì—ì„œ Pclassë¥¼ ë¨¼ì € ë¶„ì„í•´ ë³´ê² ë‹¤. ì§€ê¸ˆê¹Œì§€ í•„ìëŠ” ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ìœ¼ë©´ êµ¬ì¡°ìœ¨ì´ ë†’ë‹¤ê³  ë³´ê³  ìˆìœ¼ë©° ì§€ê¸ˆê¹Œì§€ ê·¸ ê´€ì ì— ì´ˆì ì„ ë§ì¶”ê³  EDAë¥¼ ì§„í–‰í–ˆë‹¤. 

ì´ë²ˆ íŒŒíŠ¸ì—ì„œ ê³¼ì—° ê·¸ ì¶”ì •ì´ ë§ëŠ”ì§€ í™•ì¸í•´ ë³´ê³ ì í•œë‹¤.
```
train_df['Pclass'].value_counts()
```
1ë“±ì‹¤ì— 184ëª…, 2ë“±ì‹¤ì— 216ëª…, 3ë“±ì‹¤ì— 491ëª…ìœ¼ë¡œ ì´ 891ëª…ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì‹œê°í™”ë¥¼ í†µí•´ Pclassë³„ êµ¬ì¡°ìê°€ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ í™•ì¸í•´ ë³´ê³ ì í•œë‹¤.

```
pclass = ["1", "2", "3"]
pclass_survived = {}
for i in pclass:
    total = train_df[train_df['Pclass'] == int(i)].shape[0]
    survived =  train_df[(train_df['Pclass'] == int(i)) & (train_df['Survived'] == 1)].shape[0]
    pclass_survived[i] = round(survived / total * 100, 2)

pclass_survived = pd.DataFrame.from_dict(pclass_survived, orient='index', columns=['Survival Rate (%)'])
pclass_survived = pclass_survived.reset_index()
pclass_survived.columns = ['Pclass', 'Survival Rate (%)']

custom_palette = ["#E6E6FA", "#FFA07A", "#AFEEEE"]
plt.figure()
ax = sns.barplot(x='Pclass', y='Survival Rate (%)', data=pclass_survived, palette=custom_palette)

for i, v in enumerate(pclass_survived['Survival Rate (%)']):
    ax.text(i, v, f"{v:.0f}%", color='black', ha='center', va='bottom', fontsize=10)

plt.title('Survival Rate by Pclass')
plt.xlabel('Pclass')
plt.ylabel('Survival Rate (%)')
plt.legend()
plt.show()
```
![image](https://github.com/user-attachments/assets/66fe8a23-96fa-4935-9c7a-043e91f4dac4)

ìœ„ì˜ ì‹œê°í™” ê²°ê³¼ë¥¼ í†µí•´ ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ì€ ê³³ì— ì†Œì†ë  ìˆ˜ë¡ êµ¬ì¡°ìœ¨ì´ ë†’ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì¦‰, í•„ìê°€ ì•ì—ì„œ ì „ì œë¡œ ë³´ê³  ìˆì—ˆë˜ ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ì„ ìˆ˜ë¡ êµ¬ì¡°ìœ¨ì´ ë†’ë‹¤ëŠ” ê²ƒì´ ë§ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒìœ¼ë¡œ Fare(ìš”ê¸ˆ)ì— ë”°ë¥¸ êµ¬ì¡°ìë„ ë³´ê³ ì í•œë‹¤. ìš”ê¸ˆì— ë”°ë¼ ì„ ì‹¤ ë“±ê¸‰ì— ì°¨ì´ê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì„ ì‹¤ ë“±ê¸‰ì— ë”°ë¥¸ êµ¬ì¡°ìœ¨ì„ ë¹„êµí•´ ë³´ëŠ”ë° ì¢‹ì€ ë°ì´í„°ë¼ê³  ìƒê°í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

```
train_df.groupby(['Fare','Survived'])['Survived'].count()
```
![image](https://github.com/user-attachments/assets/1c1a6e7b-6cfd-44f7-a958-b42985e1cc81)

ìš”ê¸ˆ(Fare) ì—­ì‹œ Ageì™€ ë¹„ìŠ·í•˜ê²Œ êµ‰ì¥íˆ ë³µì¡í•˜ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì—°ë ¹ëŒ€ë¥¼ êµ¬ë¶„í•œ ê²ƒì²˜ëŸ¼ ìš”ê¸ˆ ì—­ì‹œ êµ¬ë¶„ì„ ì§€ì–´ì•¼ í•  í•„ìš”ê°€ ìˆë‹¤. ë‹¹ì‹œ íƒ€ì´íƒ€ë‹‰í˜¸ì˜ í‹°ì¼“ ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ 1ë“±ì„ì€ 30íŒŒìš´ë“œ(150ë‹¬ëŸ¬), ìŠ¤ìœ„íŠ¸ 1ë“±ì„ì€ 870íŒŒìš´ë“œ(4350ë‹¬ëŸ¬), 2ë“±ì„ì€ 12íŒŒìš´ë“œ(60ë‹¬ëŸ¬), 3ë“±ì‹¤ì€ 7íŒŒìš´ë“œ(35ë‹¬ëŸ¬)ìœ¼ë¡œ êµ¬ë¶„í•˜ë ¤ê³  í–ˆìœ¼ë‚˜ ê²°ê³¼ì ìœ¼ë¡œ ë‹¬ëŸ¬ êµ¬ë¶„í–ˆì„ ë•Œ 1ë“±ê¸‰ì‹¤ì— 29ëª…, 2ë“±ê¸‰ì‹¤ì— 170ëª…, 3ë“±ê¸‰ì‹¤ì— 692ëª…ìœ¼ë¡œ ìœ„ì—ì„œ Pclassë³„ í†µê³„ì™€ ë§ì§€ ì•Šì•„ íŒŒìš´ë“œë¡œ êµ¬ë¶„í–ˆë‹¤.

```
def get_category(fare):
    cat = ''
    if fare >= 30: cat = 1
    elif fare >= 12: cat = 2
    else: cat = 3
    return cat

group_names = [1, 2, 3]
 
train_df['Fare_range'] = train_df['Fare'].apply(lambda x : get_category(x))
predict_df['Fare_range'] = predict_df['Fare'].apply(lambda x : get_category(x))

# ì‹œê°í™”
Fare_ranges = np.unique(train_df['Fare_range'].values)
Fare_range_survived = {}

for i in Fare_ranges:
    total = train_df[train_df['Fare_range'] == int(i)].shape[0]
    survived =  train_df[(train_df['Fare_range'] == int(i)) & (train_df['Survived'] == 1)].shape[0]
    if survived != 0:
        Fare_range_survived[i] = round(survived / total * 100, 2) 
    else:
        Fare_range_survived[i] = 0

fare_survived_df = pd.DataFrame.from_dict(Fare_range_survived, orient='index', columns=['Survival Rate (%)'])
fare_survived_df = fare_survived_df.reset_index()
fare_survived_df.columns = ['Fare_range', 'Survival Rate (%)']

custom_palette = ["#FF6B6B", "#FFD93D", "#9BDE7C"]
plt.figure(figsize=(10,6))
ax = sns.barplot(x='Fare_range', y='Survival Rate (%)', data=fare_survived_df, palette=custom_palette)

for i, v in enumerate(fare_survived_df['Survival Rate (%)']):
    ax.text(i, v, f"{v:.0f}%", color='black', ha='center', va='bottom', fontsize=10)

plt.title('Survival Rate by Fare Range')
plt.xlabel('Fare Range')
plt.ylabel('Survival Rate (%)')
plt.xticks(ticks=[0, 1, 2], labels=['1', '2', '3'], rotation=0)
plt.show()
```
![image](https://github.com/user-attachments/assets/126eb1c1-bb70-4ca4-9938-13e1562032ea)

ìœ„ì˜ ê·¸ë˜í”„ì²˜ëŸ¼ ìš”ê¸ˆì— ë”°ë¥¸ ì„ ì‹¤ ë“±ê¸‰ì´ ë†’ì„ ìˆ˜ë¡ êµ¬ì¡°ìœ¨ì´ ë†’ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ Fare Rangeë¥¼ í†µí•´ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆëŠ” ê²ƒì´ í•˜ë‚˜ìˆë‹¤. Fare rangeë¥¼ í†µí•´ êµ¬ë¶„í•œ 1~3 ë“±ê¸‰ì´ ê³¼ì—° kaggleì—ì„œ ì œê³µí•œ Pclassì™€ ë§ì„ì§€ì— ëŒ€í•œ ê²ƒì´ë‹¤.

```
train_df.groupby(['Pclass'])['Fare_range'].value_counts()
```
![image](https://github.com/user-attachments/assets/4fa88d46-47c8-4179-b97f-6baad1dfaf09)

Fare rangeë¥¼ í†µí•œ êµ¬ë¶„ì´ ë§ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Pclassê°€ 1ì¸ ë°˜ë©´ Fare rangeëŠ” 3ìœ¼ë¡œ 12íŒŒìš´ë“œë³´ë‹¤ ì ì€ ê°€ê²©ìœ¼ë¡œ êµ¬ë§¤í–ˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì¦‰, FareëŠ” ë‚˜ì¤‘ì— ìˆì„ ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡ì—ì„œ ì˜¤íˆë ¤ í—·ê°ˆë¦¼ì„ ì¤„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ Fareì€ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°ì— ìˆì–´ ì¤‘ìš”í•œ ë°ì´í„°ë¡œ ë³´ê¸° ì–´ë µë‹¤ê³  ìƒê°í•œë‹¤.


4. Embarked
```
print(train_df['Embarked'].count())
print(train_df[train_df['Embarked'].isna()])
```
Embarkedì˜ ê°œìˆ˜ì™€ ì¤‘ê°„ ì •ì°©ì§€ì— ë”°ë¥¸ ìƒì¡´ìì˜ ìˆ«ìë¥¼ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ ê°œìˆ˜ëŠ” 889ê°œë¡œ train dataì—ì„œ ì œê³µë˜ëŠ” 891ëª…ì˜ ìŠ¹ê°ê³¼ ë‘ ëª…ì˜ ìŠ¹ê°ì´ NaN ê°’ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ìœ„ì˜ ì½”ë“œ ì¤‘ ë§ˆì§€ë§‰ ì½”ë“œë¥¼ í†µí•´ ìŠ¹ê°ì˜ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì •ë³´ëŠ” ì•„ë˜ì˜ ì‚¬ì§„ê³¼ ê°™ë‹¤.
![image](https://github.com/user-attachments/assets/4b190b27-d054-421b-8a9f-c1dde7e3f324)

1ë“±ì‹¤ íƒ‘ìŠ¹ê°, ì—¬ì„±, ê°™ì€ ì„ ì‹¤(Cabin)ì— íƒ‘ìŠ¹í•œ ì‚¬ëŒìœ¼ë¡œ ë‘˜ ë‹¤. êµ¬ì¡°ëœ ì‚¬ëŒì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ê° Embarkedì— ë”°ë¥¸ ìƒì¡´ìœ¨ì„ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

```
embarkeds = ["C", "Q", "S"]
embarked_survived = {}

for i in embarkeds:
    total = train_df[train_df['Embarked'] == i].shape[0]
    survived =  train_df[(train_df['Embarked'] == i) & (train_df['Survived'] == 1)].shape[0]
    embarked_survived[i] = round(survived / total * 100, 2)

for i in embarked_survived:
    print(f"{i} Embarked ìƒì¡´ë¥ : {embarked_survived[i]}")


df_embarked_survived = pd.DataFrame.from_dict(embarked_survived, orient='index', columns=['Survival Rate (%)'])
df_embarked_survived = df_embarked_survived.reset_index()
df_embarked_survived.columns = ['Embarked', 'Survival Rate (%)']

custom_palette = ["#FF6B6B", "#FFD93D", "#9BDE7C"]
plt.figure()
ax = sns.barplot(x='Embarked', y='Survival Rate (%)', data=df_embarked_survived, palette=custom_palette)

for i, v in enumerate(df_embarked_survived['Survival Rate (%)']):
    ax.text(i, v, f"{v:.0f}%", color='black', ha='center', va='bottom', fontsize=10)

plt.title('Survival Rate by Embarked')
plt.xlabel('Embarked')
plt.ylabel('Survival Rate (%)')
plt.legend()
plt.show()
```
![image](https://github.com/user-attachments/assets/d437d92e-dc76-4671-b3ad-9d74a51b58f3)

íƒ€ì´íƒ€ë‹‰ì˜ ì¤‘ê°„ ì •ì°©ì§€ê°€ 1. S = ì˜êµ­ Southampton 2. C = í”„ë‘ìŠ¤ Cherbourg, 3. Q = ì•„ì¼ëœë“œ Queenstown 4. ë¯¸êµ­ New York ì´ë ‡ê²Œ ë˜ì–´ ìˆë‹¤. íƒ€ì´íƒ€ë‹‰í˜¸ëŠ” ì—¬ì • ì¤‘ê°„ì— ë‚´ë¦° ìŠ¹ê°ì€ ì—†ì—ˆìœ¼ë©° ëª¨ë‘ê°€ New Yorkìœ¼ë¡œ í–¥í•  ì˜ˆì •ì´ì—ˆë‹¤. 

ë”°ë¼ì„œ í•„ìëŠ” Embarkedê°€ NaNì¸ ë‘ ìŠ¹ê°ì€ ì—¬ì„±, 1ë“±ì‹¤, ìƒì¡´ì´ë¼ëŠ” ë°ì´í„°ë¥¼ ì´ìš©í•´ ìƒì¡´ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ Cì¸ Cherbourgë¡œ ì„ì˜ë¡œ ì±„ì›Œ ë„£ì„ ê²ƒì´ë‹¤.

```
train_df.loc[train_df['Embarked'].isna(), 'Embarked'] = 'C'
```
ë˜í•œ, EmbarkedëŠ” ì¤‘ìš”í•œ featureë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
```
embarked_pclass_counts = train_df.groupby(['Embarked', 'Pclass']).size().unstack()
embarked_pclass_counts
```
![image](https://github.com/user-attachments/assets/97b6dae7-c8e7-43b0-b5fa-971eabfc5116)

ìœ„ì˜ ê²°ê³¼ë¥¼ í†µí•´ ìŠ¹ê°ë“¤ ì¤‘ ì˜êµ­ì—ì„œ íƒ‘ìŠ¹í•œ ìŠ¹ê°ì´ ê°€ì¥ ë§ì•˜ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ì—­ì‚¬ì ìœ¼ë¡œ 1910ë…„ ëŒ€ ì˜êµ­ì€ ì„¸ê³„ì ìœ¼ë¡œ ë§ì€ ì‚¬ëŒë“¤ì´ ëª°ë¦¬ë˜ ê³³ì´ì—ˆë‹¤. ê·¸ ì´ìœ ë¡œëŠ” ì„¸ ê°€ì§€ê°€ ìˆë‹¤.
1. ì‚°ì—…í˜ëª…ê³¼ ê²½ì œì  ê¸°íšŒ
  * 18ì„¸ê¸° ì˜êµ­ì€ ì‚°ì—…í˜ëª…ì˜ ë°œìƒì§€ë¡œ ì„¸ê³„ ê²½ì œì˜ ì¤‘ì‹¬ì§€ë¡œ ì˜êµ­ìœ¼ë¡œ ì´ì£¼í•˜ê±°ë‚˜ ì¼ìë¦¬ë¥¼ ì°¾ê¸° ìœ„í•´ ì‚¬ëŒë“¤ì´ ëª°ë¦¬ë˜ ê³³ì´ì—ˆë‹¤.
2. ëŒ€ì˜ì œêµ­ì˜ ì˜í–¥ë ¥
  * ì˜êµ­ì€ ë‹¹ì‹œ ë§ì€ ì‹ë¯¼ì§€ë¥¼ ê°€ì§€ê³  ìˆì—ˆë˜ ì œêµ­ìœ¼ë¡œ ì¤‘ì‹¬ì§€ì¸ ì˜êµ­ì€ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ê¸°íšŒì˜ ë•…ì´ì—ˆë‹¤.
3. ì´ë¯¼ê³¼ ë¬´ì—­ì˜ ì¤‘ì‹¬ì§€
  * ìœ„ì˜ ë‘ ê°€ì§€ ì´ìœ ì™€ í•¨ê»˜ ì˜êµ­ì€ ë‹¹ì‹œ ë‹¤ë¥¸ ëŒ€ë¥™ ì‚¬ëŒë“¤ì—ê²Œ ì´ë¯¼ ê²½ìœ ì§€ì˜€ë‹¤. ì¦‰, ë¶ë¯¸, ì˜¤ì„¸ì•„ë‹ˆì•„ ë“±ìœ¼ë¡œ ì´ì£¼í•  ë•Œ ì˜êµ­ì„ ê±°ì³ì„œ ê°”ë‹¤.
ì´ëŸ¬í•œ ì´ìœ ì™€ í•¨ê»˜ ë‹¹ì‹œ ì•„ë©”ë¦¬ì¹¸ ë“œë¦¼ì„ ê¿ˆê¾¸ê³  ì¶œë°œí•˜ëŠ” 3ë“±ì‹¤ ìŠ¹ê°ì´ ì˜êµ­ì—ì„œ ê°€ì¥ ë§ì•˜ì„ ê²ƒì´ë¼ëŠ” ì—­ì‚¬ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ì¶”ì¸¡ê³¼ titanic data ë¶„ì„ì„ í†µí•œ ìë£Œë¥¼ í†µí•´ ì‚¬ë§ìì˜ ë§ì€ ë¹„ìœ¨ì´ ì˜êµ­ ì¦‰, Southamptonì—ì„œ ì¶œë°œí•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ í•„ìëŠ” Embarkedë¥¼ ì£¼ìš”í•œ featureë¡œ ìƒê°í•˜ê³  ìˆë‹¤.


5. Cabin
   
Cabinì— ëŒ€í•´ NaN ê°’ì„ í™•ì¸í•´ë³´ë©´ 687ëª…ì´ ì„ ì‹¤ ë²ˆí˜¸ê°€ ì—†ë‹¤. ì´ 891ëª…ì˜ ìŠ¹ê° ì¤‘ 687ëª…ì˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ í•„ìëŠ” Cabin featureì€ ì‚­ì œí•˜ê¸°ë¡œ í–ˆë‹¤.
```
train_df[train_df['Cabin'].isna()]
```


6. SibSp, Parch
   
SibSpëŠ” ê°™ì´ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤ ë˜ëŠ” ë°°ìš°ì ì¸ì› ìˆ˜ì´ë©°, ParchëŠ” ê°™ì´ íƒ‘ìŠ¹í•œ ë¶€ëª¨ë‹˜ ë˜ëŠ” ì–´ë¦°ì´ ì¸ì› ìˆ˜ì´ë‹¤. ì´ ë‘ featureê°€ ìƒì¡´ì— ì˜í–¥ì„ ì£¼ì—ˆëŠ”ì§€ëŠ” ëª¨ë¥´ì§€ë§Œ ìë£Œ ì¡°ì‚¬ ì¤‘ ë¶€ë¶€ê°€ í•¨ê»˜ íƒ‘ìŠ¹í–ˆì„ ê²½ìš° ë‚¨ì„±ì´ êµ¬ëª… ë³´íŠ¸ì— íƒ‘ìŠ¹í•˜ì§€ ëª» í•˜ì ì—¬ì„±ë„ êµ¬ëª… ë³´íŠ¸ì— íƒ‘ìŠ¹í•˜ì§€ ì•Šê³  ê°™ì´ ë°°ì—ì„œ ìµœí›„ë¥¼ ë§ì´ í–ˆë‹¤ëŠ” ë‚´ìš©ì´ ìˆì–´ ì˜ˆìƒì¹˜ ëª»í•œ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í–ˆë‹¤. ë‹¤ìŒì€ wikipediaì—ì„œ ë°œì·Œí•œ ë‚´ìš©ì´ë‹¤.

> â€œë…¸ë¶€ë¶€ ìŠ¤íŠ¸ë¼ìš°ìŠ¤ ë¶€ë¶€ëŠ” ê¸ˆìŠ¬ì´ ì¢‹ì€ ë…¸ë¶€ë¶€ì˜€ë‹¤. ì´ì§€ë„ì–´ ìŠ¤íŠ¸ë¼ìš°ìŠ¤ê°€ êµ¬ëª…ë³´íŠ¸ ìŠ¹ì„ ì„ ê±°ì ˆí•˜ì ê·¸ì˜ ë¶€ì¸ì¸ ì•„ì´ë‹¤ ìŠ¤íŠ¸ë¼ìš°ìŠ¤ë„ ì„ ì›ì˜ êµ¬ëª…ë³´íŠ¸ ìŠ¹ì„  ì œì•ˆì„ ê±°ì ˆí–ˆë‹¤.â€ - <https://ko.wikipedia.org/wiki/íƒ€ì´íƒ€ë‹‰í˜¸_ì¹¨ëª°_ì‚¬ê³ >

ì¦‰, ì´ëŸ¬í•œ ì˜ˆìƒí•˜ì§€ ëª»í•œ ë¶€ë¶„ì—ì„œ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í•´ ì œê±°í•˜ì§€ ì•Šê³  ë¶„ì„í•´ ë³´ê³ ì í•œë‹¤.
```
train_df.groupby(['SibSp','Survived'])['Survived'].count()
train_df.groupby(['Parch','Survived'])['Survived'].count()
```
![image](https://github.com/user-attachments/assets/af117f8e-7b39-4945-be93-230cf74e401d)
![image](https://github.com/user-attachments/assets/fa92109f-6e13-4898-9b4e-eef612d0bfad)

ìœ„ì˜ ì˜¤ë¥¸ ìª½ ê²°ê³¼ë¥¼ í†µí•´ í˜¼ì íƒ‘ìŠ¹í•œ ê²½ìš°, ë°°ìš°ìì™€ íƒ‘ìŠ¹í•œ ê²½ìš°, ë°°ìš°ì ë° í˜•ì œìë§¤ì™€ í•¨ê»˜ íƒ‘ìŠ¹í•œ ìŠ¹ê°ì˜ ìˆ«ìë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ParchëŠ” ê°™ì´ íƒ‘ìŠ¹í•œ ë¶€ëª¨ë‹˜ ë˜ëŠ” ì–´ë¦°ì´ ì¸ì› ìˆ˜ì´ë‹¤. ë˜í•œ, ì™¼ ìª½ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. SibSp, ParchëŠ” ë¶„ì„í•˜ê¸° ì• ë§¤í•œ ë°ì´í„°ì´ë©°, ìœ„ì—ì„œ ì†Œê°œí•œ í˜¹ì‹œ ëª¨ë¥¼ ìƒí™©ì— ì˜ˆìƒí•˜ì§€ ëª»í•œ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í•œ ë¶€ë¶„ì´ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í•„ìš” ì—†ë‹¤ê³  ìƒê°í•˜ëŠ” featureì€ ì œê±°í•˜ê³  ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©í•  featureì„ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

```
def drop_features(df):
    df.drop(['PassengerId','Name', 'Ticket', 'Cabin', 'Age', 'Fare', 'Fare_range'], axis=1, inplace=True)

    y = df['Survived']
    df = df.drop('Survived', axis=1, inplace=False)
    return df, y
    
X, y = drop_features(train_df)
feature = X.columns
predict_df = predict_df[feature]
```
![image](https://github.com/user-attachments/assets/160321bb-8be3-4afb-b5d7-e341d75848ed)

#### ëª¨ë¸ í•™ìŠµ
ëª¨ë¸ í•™ìŠµ ì „ì— ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì˜¤ì°¨í–‰ë ¬, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, f1 score, roc auc ê³¡ì„ ì„ í†µí•´ í‰ê°€ë¥¼ í•  ê²ƒì´ë‹¤.
```
ìœ¼ë¡œ ì˜¤ì°¨í–‰ë ¬, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, f1 score, roc auc ê³¡ì„ ì„ í†µí•´ í‰ê°€ë¥¼ í•  ê²ƒì´ë‹¤.

from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.model_selection import train_test_split

RANDOM_STATE = 110

def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix(y_test, pred)
    
    accuracy = accuracy_score(y_test, pred)
    
    precision = precision_score(y_test, pred, pos_label=1)
    recall = recall_score(y_test, pred, pos_label=1)
    f1 = f1_score(y_test, pred, pos_label=1)
    roc_auc = roc_auc_score(y_test, pred_proba)
    
    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
```
ìœ„ì˜ ì½”ë“œë¥¼ í†µí•´ ë§¤ë²ˆ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ í‰ê°€ë¥¼ ì§„í–‰í•  ê²ƒì´ë‹¤. ì˜¤ì°¨í–‰ë ¬, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, f1 score, roc auc ê³¡ì„ ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ë¤„ë³¼ ì˜ˆì •ì´ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ë§¤ë²ˆ ê°™ì€ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ ìœ„ì— ì„ ì–¸ëœ RANDOM_STATEë¥¼ ì´ìš©í•  ê²ƒì´ë‹¤.
 
   ##### RandomForestClassifier
ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì•™ìƒë¸” í•™ìŠµ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥ ë•ë¶„ì— ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆë‹¤. ì´ë¦„ì„ í†µí•´ ìœ ì¶”í•  ìˆ˜ ìˆë“¯ì´ ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬(Decision Tree)ë¥¼ ëœë¤í•˜ê²Œ ë§Œë“¤ì–´ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•œë‹¤.

ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ì…ë ¥í•œ í›ˆë ¨ ë°ì´í„°ì—ì„œ ëœë¤í•˜ê²Œ ìƒ˜í”Œì„ ì¶”ì¶œí•´ í›ˆë ¨ ë°ì´í„°ë¥¼ ë§Œë“¤ë©° ì´ë•Œ ìƒ˜í”Œì´ ì¤‘ë³µë˜ì–´ ì¶”ì¶œë  ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ ìƒ˜í”Œì„ ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì´ë¼ í•œë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ê° ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ëª¨ë“  íŠ¹ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¼ë¶€ íŠ¹ì„±ë§Œì„ ì‚¬ìš©í•´ ê° íŠ¸ë¦¬ê°€ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì„±ì¥í•˜ê²Œ ë˜ë©°, íŠ¸ë¦¬ë“¤ ê°„ì˜ ë‹¤ì–‘ì„±ì´ ì¦ê°€í•˜ê²Œ ëœë‹¤.

ì´ëŸ¬í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ë§Œ 'ë§ì€ íŠ¸ë¦¬ë¥¼ í•™ìŠµì‹œí‚¤ê³  ì˜ˆì¸¡ì„ ê²°í•©í•˜ê¸° ë•Œë¬¸ì— ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆë‹¤'. ë˜í•œ, 'ì—¬ëŸ¬ íŠ¸ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•´ì•¼ í•˜ë¯€ë¡œ, ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ì„ ìˆ˜ ìˆë‹¤.' ì´ëŸ¬í•œ ë‹¨ì ì´ ìˆë‹¤. ëœë¤ í¬ë ˆìŠ¤íŠ¸ì— ëŒ€í•œ ì„¤ëª…ì€ ì—¬ê¸°ê¹Œì§€ í•˜ê² ë‹¤.
```
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

rf_clf = RandomForestClassifier(random_state=RANDOM_STATE)
rf_clf.fit(X_train , y_train)
pred = rf_clf.predict(X_test)

# feature importance ì¶”ì¶œ 
feature_names = train_df.columns.drop('Survived')

# feature importanceë¥¼ column ë³„ë¡œ ì‹œê°í™” í•˜ê¸° 
sns.barplot(x=rf_clf.feature_importances_ , y=feature_names)

pred = rf_clf.predict(X_train) 
proba = rf_clf.predict_proba(X_train)[:, 1]

rf_pred = rf_clf.predict(X_test) 
rf_proba = rf_clf.predict_proba(X_test)[:, 1]

get_clf_eval(y_train, pred, proba)
get_clf_eval(y_test, rf_pred, rf_proba)
```
![image](https://github.com/user-attachments/assets/61227a19-b5a9-49cf-93be-9387a8599b93)

feature ì¤‘ìš”ë„ë¥¼ í†µí•´ Sex, Pclass, Age_rangeê°€ ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©ëœ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

ëª¨ë¸ì„ í•™ìŠµí•˜ê³  kaggleì—ì„œ ì œê³µí•œ gender_submission.csvë¥¼ í†µí•´ ì œì¶œí•˜ë©´ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```
predict_titanic_pred_rf = rf_clf.predict(predict_df)

gender_submission_df['Survived'] = predict_titanic_pred_rf
gender_submission_df.to_csv('titanic_submission_rf.csv',index=False)
```
![image](https://github.com/user-attachments/assets/eddc5f4b-8651-4cf7-9ff7-202d45b7901b)

í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•˜ì§€ ì•Šê³  ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ kaggleì—ì„œ ì ìˆ˜ëŠ” 0.77751ì´ ë‚˜ì™”ë‹¤. ì´ë²ˆì—ëŠ” ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ì´ìš©í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ë ¤ê³  í•œë‹¤.
```
from sklearn.model_selection import GridSearchCV

params = {
    'max_depth': np.arange(1, 10, 1),
    'min_samples_leaf' : np.arange(1, 40, 1),
    'min_samples_split' : np.arange(2, 40, 1)
}

rf_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True)
grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )
grid_cv.fit(X_train , y_train)

print('ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°:\n', grid_cv.best_params_)
print('ìµœê³  ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(grid_cv.best_score_))

best_rf = grid_cv.best_estimator_

# feature importance ì¶”ì¶œ 
feature_names = train_df.columns.drop('Survived')

# feature importanceë¥¼ column ë³„ë¡œ ì‹œê°í™” í•˜ê¸° 
sns.barplot(x=best_rf.feature_importances_ , y=feature_names)


pred = best_rf.predict(X_train) 
proba = best_rf.predict_proba(X_train)[:, 1]

best_rf_pred = best_rf.predict(X_test) 
best_rf_proba = best_rf.predict_proba(X_test)[:, 1]

get_clf_eval(y_train, pred, proba)
get_clf_eval(y_test , best_rf_pred, best_rf_proba)
```
ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°:{'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 29}
ìµœê³  ì˜ˆì¸¡ ì •í™•ë„: 0.8026

ì´ë ‡ê²Œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
<img width="554" alt="image" src="https://github.com/user-attachments/assets/c9207221-8e60-47bd-ac61-dfc9f103ce44">
```
ì˜¤ì°¨ í–‰ë ¬
[[355  29]
 [ 87 152]]
ì •í™•ë„: 0.8138, ì •ë°€ë„: 0.8398, ì¬í˜„ìœ¨: 0.6360,    F1: 0.7238, AUC:0.8742
ì˜¤ì°¨ í–‰ë ¬
[[151  14]
 [ 35  68]]
ì •í™•ë„: 0.8172, ì •ë°€ë„: 0.8293, ì¬í˜„ìœ¨: 0.6602,    F1: 0.7351, AUC:0.8850
```
ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì •í•´ì•¼ í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¡œ, ëª¨ë¸ì˜ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ì´ ë•Œ ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ìê°€ ì„¤ì •í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ë“¤ì˜ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ íƒìƒ‰í•˜ì—¬ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ì¡°í•©ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤€ë‹¤. ë”°ë¼ì„œ ê²°ê³¼ë¡œ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì´ ë‚˜ì˜¤ê³  ê·¸ ê°’ì„ í† ëŒ€ë¡œ í›ˆë ¨ì„ í–ˆì„ ë•Œ feature importanceë¥¼ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ì´ìš©í•œ ëª¨ë¸ì€ Sex, Pclassë¥¼ ì¤‘ìš”í•œ íŠ¹ì„±ìœ¼ë¡œ ì‚¬ìš©í–ˆë‹¤. 

ê·¸ë¦¬ë“œì„œì¹˜ë¥¼ ì‚¬ìš©í•´ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•œ í›„ kaggleì— ì œì¶œí–ˆì„ ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ ì–»ì—ˆë‹¤. ê¸°ì¡´ 0.77751 ë³´ë‹¤ ì‚´ì§ ë†’ì€ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤.

<img width="711" alt="image" src="https://github.com/user-attachments/assets/19762fd2-6862-4236-a692-aeafbee821d2">

kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
   
   ##### XGBoost
XGBoost ë˜í•œ Randomforestì™€ ê°™ê²Œ ì²˜ìŒì—ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•˜ì§€ ì•Šê³  ê¸°ë³¸ì ìœ¼ë¡œ ì§„í–‰í•´ ë³´ê³  XGBoostë¶€í„°ëŠ” ê·¸ë¦¬ë“œì„œì¹˜ê°€ ì•„ë‹Œ Hyperoptë¥¼ ì´ìš©í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ê³ ì í•œë‹¤.
```
ë¦¬ë“œì„œì¹˜ê°€ ì•„ë‹Œ Hyperoptë¥¼ ì´ìš©í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ê³ ì í•œë‹¤.

from xgboost import XGBClassifier, plot_importance

xgb = XGBClassifier(random_state=RANDOM_STATE)
xgb.fit(X_train, y_train, verbose=True)

xgb_preds = xgb.predict(X_test)
xgb_pred_proba = xgb.predict_proba(X_test)[:, 1]

get_clf_eval(y_test , xgb_preds, xgb_pred_proba)

fig, ax = plt.subplots(figsize=(10, 5))
plot_importance(xgb, ax=ax)
```
<img width="708" alt="image" src="https://github.com/user-attachments/assets/a39a5fa5-b25d-4a9b-8edc-2a590fe0be04">

randomforestì™€ ë‹¤ë¥´ê²Œ Sexì™€ Pclass ë³´ë‹¤ Age_rangeê°€ ì¤‘ìš”í•˜ê²Œ ì‘ìš©í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. F1 scoreê°€ ì¡°ê¸ˆ ë” ë†’ê²Œ ë‚˜ì™”ì§€ë§Œkaggleì— ì œì¶œí–ˆì„ ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì˜¤íˆë ¤ randomforestë¡œ í•™ìŠµí–ˆì„ ë•Œ ë³´ë‹¤ ë” ë‚®ê²Œ ë‚˜ì™”ë‹¤.
<img width="708" alt="image" src="https://github.com/user-attachments/assets/074bd4fd-4567-4c86-b07b-bac7aec6fb7e">

ì˜¤ì°¨í–‰ë ¬ì„ í†µí•´ ê²°ê³¼ë¥¼ ì¢€ë” ìì„¸í•˜ê²Œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
<img width="708" alt="image" src="https://github.com/user-attachments/assets/5e06b315-e61d-471b-a8b4-4b4e771264bd">

ìœ„ì—ê°€ train data, ì•„ë˜ê°€ test_dataë¡œ ì˜ˆì¸¡í–ˆì„ ë•Œì˜ ê²°ê³¼ì´ë‹¤. ê³¼ì í•©ì´ ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ì˜¤ì°¨í–‰ë ¬ì„ í†µí•´ False Positive, False Negative ì—­ì‹œ ë†’ê²Œ ë‚˜ì˜¨ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¦‰, ì ìˆ˜ëŠ” ë†’ì§€ë§Œ ì˜ˆì¸¡ì„ ì œëŒ€ë¡œ í•˜ì§€ ëª» í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ ë³´ê² ë‹¤.
```
from hyperopt import hp, fmin, tpe, Trials
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score

xgb_search_space = {'max_depth': hp.quniform('max_depth', 2, 15, 1), 
                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),
                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),
                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}

def objective_func(search_space):
    xgb_clf = XGBClassifier(n_estimators=100,
                            max_depth=int(search_space['max_depth']),
                            min_child_weight=int(search_space['min_child_weight']),
                            colsample_bytree=search_space['colsample_bytree'],
                            learning_rate=search_space['learning_rate'],
                            early_stopping_rounds=30,
                            eval_metric='logloss',
                           random_state=RANDOM_STATE)
    
    roc_auc_list= []
    kf = KFold(n_splits=5)
    
    for tr_index, val_index in kf.split(X_train):
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
        
        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)], verbose=False)
        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
        roc_auc_list.append(score)
    return -1 * np.mean(roc_auc_list)

trials = Trials()
best = fmin(fn=objective_func,
            space=xgb_search_space,
            algo=tpe.suggest,
            max_evals=50, # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
            trials=trials,
            rstate=np.random.default_rng()
           )
print('best:', best)

xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'], 5),
                        max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']), 
                        colsample_bytree=round(best['colsample_bytree'], 5), random_state=RANDOM_STATE)

xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric="auc",eval_set=[(X_tr, y_tr), (X_val, y_val)])
xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])
print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
```
hyperoptë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ê¸° ìœ„í•´ ìœ„ì™€ ê°™ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

best: {'colsample_bytree': 0.613363205874114, 'learning_rate': 0.12571035945607772, 'max_depth': 11.0, 'min_child_weight': 2.0}

<img width="708" alt="image" src="https://github.com/user-attachments/assets/ab576b85-5e03-451a-afcf-8edfe0473fb3">

í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ íŠœë‹í•˜ê¸° ì „ì˜ XGBoostë³´ë‹¤ ê³¼ì í•©ì´ ë§ì´ í•´ì†Œëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

<img width="708" alt="image" src="https://github.com/user-attachments/assets/5aabc934-26fb-46ca-a336-bd2a9ab986de">

ì ìˆ˜ê°€ ë” ë†’ê²Œ ë‚˜ì˜¤ê¸´ í–ˆì§€ë§Œ randomforestë³´ë‹¤ ë‚®ì€ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì •ë°€ë„ì™€ AUCê°€ ë†’ì€ ë°˜ë©´, ì¬í˜„ìœ¨ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ë‹¤ëŠ” ì ì—ì„œ, ëª¨ë¸ì´ ì–‘ì„±ì„ ì¡ì•„ë‚´ëŠ” ëŠ¥ë ¥ì´ ë¶€ì¡±í•´ ì ìˆ˜ê°€ ë‚®ì€ ê²ƒì´ë‹¤.

   ##### LightGBM
LightGBM ì—­ì‹œ XGBoostì™€ ê°™ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ì§€ ì•Šê³  ëª¨ë¸ì„ í•™ìŠµí•´ë³´ê³  hyperoptë¡œ í•™ìŠµì„ í•œ í›„ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì€ í›„ ëª¨ë¸ì„ í•™ìŠµí•´ ë³´ê² ë‹¤.
```
from lightgbm import early_stopping
from lightgbm import LGBMClassifier

lgbm = LGBMClassifier(random_state=RANDOM_STATE)

evals = [(X_tr, y_tr), (X_val, y_val)]
lgbm.fit(X_tr, y_tr, callbacks=[early_stopping(stopping_rounds=50)], eval_metric="logloss", eval_set=evals)

preds = lgbm.predict(X_test)
pred_proba = lgbm.predict_proba(X_test)[:, 1]
get_clf_eval(y_test, preds, pred_proba)
```
<img width="624" alt="image" src="https://github.com/user-attachments/assets/421726a3-de16-4c92-a37d-028febd68ebc">

ê¸°ë³¸ì ìœ¼ë¡œ í–ˆì„ ë•Œë„ XGBoostì™€ ë¹„êµí–ˆì„ ë•Œ ê´œì°®ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•œ XGBoostì™€ ë¹„êµí–ˆì„ ë•Œ ì¬í˜„ìœ¨ì´ ì•½ê°„ ë‚®ì•„ì ¸ ëª¨ë¸ì´ ì–‘ì„± ë°ì´í„°ë¥¼ ì ê²Œ íƒì§€í•˜ì§€ë§Œ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•˜ì§€ ì•Šì•˜ë‹¤ëŠ” ì ì—ì„œ ê´œì°®ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

<img width="727" alt="image" src="https://github.com/user-attachments/assets/dfead156-2421-431f-82ef-e099d5aa5f3b">

ê¸°ë³¸ XGBoostë¥¼ ì‚¬ìš©í–ˆì„ ë•Œë³´ë‹¤ í™•ì‹¤ ë” ë†’ì€ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì´ì œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ê² ë‹¤.
```
from hyperopt import hp, fmin, tpe, Trials
from sklearn.model_selection import KFold
from sklearn.metrics import f1_score, roc_auc_score
from lightgbm import early_stopping, LGBMClassifier
import numpy as np

lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 10, 40, 1),
                     'max_depth': hp.quniform('max_depth', 5, 20, 1),
                     'min_child_samples': hp.quniform('min_child_samples', 30, 100, 1),
                     'subsample': hp.uniform('subsample', 0.7, 1),
                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.1)}

def objective_func(search_space):
    lgbm_clf =  LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),
                               max_depth=int(search_space['max_depth']),
                               min_child_samples=int(search_space['min_child_samples']),
                               subsample=search_space['subsample'],
                               verbose=-1,
                               learning_rate=search_space['learning_rate'])
    f1_list = []
    kf = KFold(n_splits=5)
    
    for tr_index, val_index in kf.split(X_train):
        X_tr, X_val = X_train.iloc[tr_index], X_train.iloc[val_index]
        y_tr, y_val = y_train.iloc[tr_index], y_train.iloc[val_index]
        
        lgbm_clf.fit(X_tr, y_tr, callbacks=[early_stopping(stopping_rounds=50)], eval_set=[(X_tr, y_tr), (X_val, y_val)], eval_metric='logloss')
        score = f1_score(y_val, lgbm_clf.predict(X_val))
        f1_list.append(score)
    
    return -1 * np.mean(f1_list)

trials = Trials()
best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,
            max_evals=50, trials=trials, rstate=np.random.default_rng(seed=30))

lgbm_clf =  LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),
                           max_depth=int(best['max_depth']),
                           min_child_samples=int(best['min_child_samples']),
                           subsample=round(best['subsample'], 5),
                           learning_rate=round(best['learning_rate'], 5))

lgbm_clf.fit(X_train, y_train, callbacks=[early_stopping(stopping_rounds=100)], eval_metric="logloss", eval_set=[(X_train, y_train), (X_test, y_test)])

lgbm_pred = lgbm_clf.predict(X_test)
lgbm_proba = lgbm_clf.predict_proba(X_test)[:, 1]

lgbm_f1_score = f1_score(y_test, lgbm_pred)
lgbm_roc_score = roc_auc_score(y_test, lgbm_proba)
```
<img width="497" alt="image" src="https://github.com/user-attachments/assets/6a054da1-0f42-47a4-9fe3-784a245da7bb">

f1 scoreì˜ ê²½ìš° ê°€ì¥ ë†’ê²Œ ë‚˜ì™”ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ì¬í˜„ìœ¨ì´ 0.7379ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤¬ë˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•œ randomforestë³´ë‹¤ ë†’ê²Œ  ë‚˜ì™”ë‹¤. kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

<img width="698" alt="image" src="https://github.com/user-attachments/assets/448baa3c-28fa-4f99-9082-e293116fda38">

0.78229ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì™”ë‹¤. 

   ##### CatBoost
CatBoost ë˜í•œ ìœ„ì—ì„œ í–ˆë˜ ë°©ë²•ëŒ€ë¡œ ì§„í–‰í•´ë³´ê² ë‹¤. ë‹¨, ì´ë²ˆì—ëŠ” hyperoptê°€ ì•„ë‹Œ optunaë¥¼ ì‚¬ìš©í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ë ¤ê³  í•œë‹¤.
```
from catboost import CatBoostClassifier

cat = CatBoostClassifier(random_state=RANDOM_STATE)
cat.fit(X_train, y_train)
```
<img width="510" alt="image" src="https://github.com/user-attachments/assets/7dc2ac2d-7666-4a58-8ff3-72d73f32bde7">

LiightGBMë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤.

<img width="678" alt="image" src="https://github.com/user-attachments/assets/01e4e84f-92a1-46a1-8541-0250bb205dac">

randomforestë¡œ í•™ìŠµí–ˆì„ ë•Œì™€ ê°™ì€ ì ìˆ˜ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ì´ì œ optunaë¥¼ í†µí•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ë³´ê² ë‹¤.
```
from sklearn.model_selection import cross_val_score
import optuna

def objective(trial):
    iterations = trial.suggest_int('iterations', 100, 1000, step=10)
    learning_rate = trial.suggest_float('learning_rate', 0.1, 1.0, step=0.1)
    depth = trial.suggest_int('depth', 3, 15)
    l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 0.1, 10.0)
    bagging_temperature = trial.suggest_float('bagging_temperature', 0.0, 1.0)
    class_weight = trial.suggest_float('class_weight', 1.0, 50.0)
    random_strength = trial.suggest_float('random_strength', 0.0, 10.0)
    od_wait = trial.suggest_int('od_wait', 10, 50)


    model = CatBoostClassifier(
        iterations=iterations,
        learning_rate=learning_rate,
        depth=depth,
        l2_leaf_reg=l2_leaf_reg,
        bagging_temperature=bagging_temperature,
        class_weights=[1, class_weight],
        random_strength=random_strength,
        od_wait=od_wait,
        random_state=RANDOM_STATE,
        verbose=0
    )
    
    model.fit(X_train, y_train)
    y_val_pred = model.predict(X_test)
    f1 = f1_score(y_test, y_val_pred, pos_label=0)
    print(f"Trial {trial.number} finished with F1 score: {f1}")
    return f1


study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100, n_jobs=-1)

best_params = study.best_params
print("Best params: ", best_params)


if 'class_weight' in best_params:
    best_params['class_weights'] = [1, best_params.pop('class_weight')]

best_cat_model = CatBoostClassifier(**best_params, random_state=RANDOM_STATE)
best_cat_model.fit(X_train, y_train)
```
<img width="510" alt="image" src="https://github.com/user-attachments/assets/295315af-7a2f-4697-adfa-d64da765e149">

ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©° kaggleì— ì œì¶œí•˜ë©´ 0.77990ìœ¼ë¡œ randomforestì™€ ê°™ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤. 

<img width="687" alt="image" src="https://github.com/user-attachments/assets/b42c2dc6-cacd-4397-b93f-412e9395351b">

ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì€ ê²ƒì€ LightGBMìœ¼ë¡œ 0.78229ì´ë‹¤. 

#### ê²°ë¡ 
kaggleì—ì„œ ì œê³µí•˜ëŠ” titanic dataë¥¼ ì´ìš©í•´ ë¶„ì„ì„ ì§„í–‰í–ˆìœ¼ë©°, ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ì ìˆ˜ë¥¼ ì–»ëŠ” ê³¼ì •ì„ ì§„í–‰í–ˆë‹¤. ì´ ë¶€ë¶„ì—ì„œ ëŠë‚€ ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 891ê°œì˜ ë°ì´í„°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì„ ì´ìš©í•˜ëŠ” ë°ì—ëŠ” ë¶€ì¡±í•œ ë°ì´í„°ì´ë©° feature ì—­ì‹œ ë§ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ê²ƒì„ ëŠê¼ˆë‹¤. ë˜í•œ, feature ì¤‘ì—ì„œ ìƒì¡´ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ì´ Sex, Pclass, Ageë¡œ ìƒê°í•˜ê³  ìˆëŠ”ë° ì´ ê²ƒìœ¼ë¡œëŠ” ìƒì¡´ ìœ ë¬´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°ì—ëŠ” í•œê³„ê°€ ìˆë‹¤ê³  ëŠê¼ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë“¯ ë¶€ë¶€ê°€ í•¨ê»˜ íƒ€ì´íƒ€ë‹‰í˜¸ì— íƒ‘ìŠ¹í•´ ìˆë‹¤ê°€ ë¶€ì¸ì€ êµ¬ëª…ë³´íŠ¸ì— íƒ‘ìŠ¹í–ˆì§€ë§Œ ë‚¨í¸ì€ ë‚¨ì„±ì´ë¼ëŠ” ì´ìœ ë¡œ íƒ‘ìŠ¹í•˜ì§€ ëª» í–ˆì„ ë•Œ, ë¶€ì¸ì´ ë‚¨í¸ê³¼ ê°™ì´ í•˜ê² ë‹¤ê³  íƒ‘ìŠ¹í•˜ì§€ ì•Šì„ ë•Œ, ì–´ë¦° ì•„ì´ì§€ë§Œ ë¶€ëª¨ë¥¼ ì°¾ì§€ ëª» í•´ì„œ ê°ì‹¤ ì•ˆì— ê³„ì† ë¨¸ë¬¼ë‹¤ê°€ êµ¬ì¡°ë˜ì§€ ëª»í•œ ì‚¬ë¡€ ë“±ë“± ì˜ˆìƒí•˜ì§€ ëª»í•˜ëŠ” ë¶€ë¶„ì´ ë§ì´ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ Cabinì˜ ê²½ìš° NaN ê°’ì´ 687ê°œë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” featureì˜€ë‹¤. ì¤‘ìš”í•œ feature ì¤‘ í•˜ë‚˜ì¸ Ageì˜ ê²½ìš°ì—ë„ NaN ê°’ì´ 177ê°œë¡œ ë§ì•˜ë‹¤. 

ì´ì²˜ëŸ¼ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì•„ì‰¬ìš´ ë¶€ë¶„ì€ ì—­ì‹œ ë°ì´í„°ì˜ ë¶€ì¡±ì´ì—ˆë‹¤. ë”°ë¼ì„œ íŠ¹ì • ì ìˆ˜ ì´ìƒì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì–»ì§€ ëª» í–ˆë‹¤ëŠ” ë°ì— í•œê³„ê°€ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²• ì—­ì‹œ ë‹¤ì–‘í•˜ë©°, random_stateë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëƒì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— í˜„ì¬ ì ìˆ˜ë¥¼ ê°œì„ í•  ë°©ë²•ì€ ë‹¤ì–‘í•˜ê²Œ ìˆë‹¤.

titanic dataë¥¼ ì´ìš©í•´ EDAë¥¼ ì§„í–‰í•˜ê³  ê°„ë‹¨í•˜ê²Œ modelì„ í•™ìŠµí•˜ëŠ” ê²ƒì€ ë¨¸ì‹ ëŸ¬ì‹ ì— ì…ë¬¸í•  ë•Œ ê°€ì¥ ë§ì´ ì ‘í•˜ëŠ” ê²ƒì´ë‹¤. í•„ì ì—­ì‹œ ì²˜ìŒ ê³µë¶€ë¥¼ í•  ë•Œ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡ì„ ì—°ìŠµìœ¼ë¡œ ì ‘í–ˆì—ˆë‹¤. í•˜ì§€ë§Œ ì´ë²ˆì— ìƒˆë¡­ê²Œ ë¶„ì„ì„ í•˜ë©´ì„œ ì´ì „ì— í–ˆë˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ê³¼ê±°ì™€ í˜„ì¬ì˜ ì°¨ì´ë¥¼ ëŠë¼ê²Œ ë˜ì—ˆë‹¤. ì²˜ìŒ ì ‘í•  ë‹¹ì‹œì—ëŠ” ìƒì¡´ìì™€ ì‚¬ë§ìì˜ ë¹„ìœ¨ì„ í†µí•´ ë°ì´í„°ì˜ ë¶ˆê· í˜•ì— ëŒ€í•´ ìƒê°í•´ë³´ì§€ ì•Šì•˜ê³ , ë‹¤ë¥¸ ì‚¬ëŒ(ë¸”ë¡œê·¸, ê°•ì˜)ì˜ ë°©ë²•ì„ ë”°ë¼í•˜ëŠ” ì½”ë“œ ì‚¬ìš©ìœ¼ë¡œ ì£¼ê´€ì ì¸ ìƒê°ì´ ë“¤ì–´ê°€ì§€ ì•Šì•˜ë‹¤. ê·¸ë¦¬ê³  Feature engineeringì´ ì•„ë‹Œ modelì— ì˜ì¡´í–ˆë‹¤. ê·¸ë˜ì„œ íŠ¹ì • ì ìˆ˜ ì´ìƒì„ ì˜¬ë¼ê°€ì§€ ëª» í–ˆì—ˆë‹¤. ë¬¼ë¡  ì§€ê¸ˆë„ ë§ì´ ë¶€ì¡±í•˜ì§€ë§Œ ê·¸ì „ì— ë„˜ì§€ ëª»í•œ ì ìˆ˜ë¥¼ ë„˜ê²¼ë‹¤ëŠ” ê²ƒì— ì˜ì˜ë¥¼ ë‘ê³  ìˆë‹¤.

ì¶”ê°€ì ìœ¼ë¡œ kaggleì—ì„œ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ëŠë‚€ ì ì€ cheating, data leakageë¥¼ í†µí•´ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ì€ ì‚¬ëŒë“¤ì´ ë§ë‹¤ëŠ” ê²ƒì„ ëŠê¼ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ tatinic <https://titanicfacts.net/titanic-survivors-list/>ì— titanicì— íƒ‘ìŠ¹í•œ ì‚¬ëŒë“¤ì˜ listê°€ ìˆë‹¤. ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•´ êµ¬ëª…ë³´íŠ¸ì— íƒ‘ìŠ¹í–ˆëŠ”ì§€ ì—¬ë¶€ì— ëŒ€í•´ ì•Œì•„ë‚´ì„œ í•™ìŠµì„ í–ˆë‹¤. ìë£Œì¡°ì‚¬ë¥¼ í†µí•´ì„œ ì–»ì€ ì •ë³´ë¼ê³  í•  ìˆ˜ ìˆê² ì§€ë§Œ í•„ìëŠ” ì´ ë°©ë²•ì€ ë‹µì„ ì•Œì•„ë‚´ì„œ ì§„í–‰í•œ ë°©ë²•ì´ë¼ê³  ìƒê°í•˜ê³  ìˆì–´ í•™ìŠµì„ í•˜ëŠ” ë° ì¢‹ì€ ë°©ë²•ì€ ì•„ë‹ˆë¼ê³  ìƒê°í•œë‹¤. 

ì¶”ê°€ì ìœ¼ë¡œ ìœ íŠœë¸Œ, êµ¬ê¸€ë§ ë“± ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì„ ì¶”ê°€í•´ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ë³´ì•˜ì§€ë§Œ ê°œì¸ì ìœ¼ë¡œ ë¶„ì„í•˜ë©° ì–»ì€ ì ìˆ˜ê°€ ê°€ì¥ ë†’ê²Œ ë‚˜ì™”ë‹¤. titanic dataë¥¼ í† ëŒ€ë¡œ ë¶„ì„í•˜ëŠ” ê²ƒì€ ì—¬ê¸°ê¹Œì§€ í•˜ê³  kaggleì—ì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ ë¶„ì„ì„ í•´ë³¼ ì˜ˆì •ì´ë‹¤.
